<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Exercise : Processing Data in a Data Lake</title>
  <script src="scripts/clipboard.min.js"></script>
  <script src="scripts/copybutton.js"></script>

<style>
    html, body, footer {
        font-family: "Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif;
        margin: 1em;
    }

    img:not(.clipboard){
        max-width: 100%;
        height: auto;
        width: auto;
    }

    /* Copy buttons */
    button.copybtn {
        webkit-transition: opacity .3s ease-in-out;
        -o-transition: opacity .3s ease-in-out;
        transition: opacity .3s ease-in-out;
        opacity: 0;
        padding: 2px 6px;
        position: absolute;
        right: 4px;
        top: 4px;
    }
    div.sourceCode:hover .copybtn, div.sourceCode .copybtn:focus {
        opacity: .3;
    }
    div.sourceCode .copybtn:hover {
        opacity: 1;
    }
    div.sourceCode {
        position: relative;
    }
    .xmodule_display.xmodule_HtmlBlock ol {
        padding: 0 0 0 2em !important;
    }
    .xmodule_display.xmodule_HtmlBlock ul {
        padding: 0 0 0 2em !important;
    }

    code {
        padding: 2px 4px !important;
        background-color: #eee !important;
        border-radius: 4px;
    }
    pre code {
        padding: 9.5px !important;
        background-color: #f5f5f5 !important;
        display: block;
        overflow-x: auto;
        margin: 0 0 10px;
        font-size: 13px;
        line-height: 1.42857143;
        word-break: break-all;
        word-wrap: break-word;
        border: 1px solid #ccc;
        border-radius: 4px;
        white-space: pre;
    }
    pre code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    pre code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    pre code span.at { color: #7d9029; } /* Attribute */
    pre code span.bn { color: #40a070; } /* BaseN */
    pre code span.bu { color: #06287e; } /* BuiltIn */
    pre code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    pre code span.ch { color: #4070a0; } /* Char */
    pre code span.cn { color: #880000; } /* Constant */
    pre code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    pre code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    pre code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    pre code span.dt { color: #902000; } /* DataType */
    pre code span.dv { color: #40a070; } /* DecVal */
    pre code span.er { color: #ff0000; font-weight: bold; } /* Error */
    pre code span.ex { color: #06287e; } /* Extension */
    pre code span.fl { color: #40a070; } /* Float */
    pre code span.fu { color: #06287e; } /* Function */
    pre code span.im { } /* Import */
    pre code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    pre code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    pre code span.op { color: #666666; } /* Operator */
    pre code span.ot { color: #007020; } /* Other */
    pre code span.pp { color: #bc7a00; } /* Preprocessor */
    pre code span.sc { color: #4070a0; } /* SpecialChar */
    pre code span.ss { color: #bb6688; } /* SpecialString */
    pre code span.st { color: #4070a0; } /* String */
    pre code span.va { color: #19177c; } /* Variable */
    pre code span.vs { color: #4070a0; } /* VerbatimString */
    pre code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

    footer {
        padding-top: 3em;
        font-style: italic;
        font-size: .9em;
    }
</style>
<body>
<p><em>[version_1.1]</em></p>
<div style="background-color: #FFD2D2; padding: 15px; margin-bottom: 25px">
<h3>
<span class="fa fa-info-circle"></span> Note
</h3>
<p>The exercises in this course will have an associated charge in your AWS account. In this exercise, you will create the following resources:</p>
<ul>
<li>AWS Glue crawlers</li>
<li>Amazon Simple Storage Service (Amazon S3) bucket</li>
<li>Amazon Athena query</li>
<li>AWS Identity and Access Management (IAM) roles (created by AWS CloudFormation)</li>
</ul>
<p><strong>The final exercise task includes instructions to delete all the resources that you create for this exercise.</strong></p>
<p>Familiarize yourself with <strong><a href="https://aws.amazon.com/glue/pricing/" target="_blank">AWS Glue pricing</a></strong>, <strong><a href="https://aws.amazon.com/s3/pricing/" target="_blank">Amazon S3 pricing</a></strong>, <strong><a href="https://aws.amazon.com/athena/pricing/" target="_blank">Amazon Athena pricing</a></strong>, and the <strong><a href="https://aws.amazon.com/free/" target="_blank">AWS Free Tier</a></strong>.</p>
</div>
<h1 id="exercise-processing-data-in-a-data-lake">Exercise : Processing Data in a Data Lake</h1>
<p>In this exercise, you will define a database and configure a crawler to explore data in an S3 bucket. Next, you will create a table. You will then transform the comma-separated values (CSV) file into Apache Parquet and create a table for the Parquet data. Finally, you will query the data with Amazon Athena.</p>
<h2 id="setting-up">Setting up</h2>
<p>This exercise requires an IAM role and an S3 bucket. You will create these resources by using the provided CloudFormation template.</p>
<ol type="1">
<li><p>Download the following CloudFormation template: <a href="downloads/exercise-processing.yml">exercise-processing.yml</a>. This template will set up the backend resources that you need to complete the exercise.</p>
<p><strong>Note</strong>: If you have an existing virtual private cloud (VPC) with the Classless Inter-Domain Routing (CIDR) block <em>10.16.0.0/16</em>, you must edit the template and change its CIDR block.</p></li>
<li><p>Sign in to the AWS Management Console as a user that has the necessary permissions to create an IAM role and CloudFormation stack.</p>
<p>You already created the CloudFormation role in Exercise 2 of this course. If you donâ€™t have a user or role that has the permissions to create a stack in AWS CloudFormation, you must create the user or role before you proceed to the next step.</p>
<p>If you need instructions for how to create a role, see the <strong>Setting up</strong> task in Exercise 2.</p></li>
<li><p>After you create the user or role to have permissions to work with AWS CloudFormation, open the <strong>CloudFormation</strong> console.</p>
<p><strong>Note</strong>: Make sure that you are in the <strong>US East (N. Virginia)</strong> Region.</p></li>
<li><p>Choose <strong>Create stack</strong>.</p></li>
<li><p>In the <strong>Specify template</strong> section, choose <strong>Upload a template file</strong>.</p></li>
<li><p>Select <strong>Choose file</strong>, browse to where you downloaded the <code>exercise-processing</code> template, and select the template.</p></li>
<li><p>Choose <strong>Next</strong>.</p></li>
<li><p>For <strong>Stack name</strong>, enter <code>exercise-processing</code>.</p></li>
<li><p>Choose <strong>Next</strong>, and then choose <strong>Next</strong> again.</p></li>
<li><p>Select the acknowledgement, and choose <strong>Create stack</strong>.</p></li>
<li><p>After the stack is created, choose the <strong>Outputs</strong> tab and copy the name of the S3 bucket.</p></li>
</ol>
<h2 id="task-1-discovering-the-data">Task 1: Discovering the data</h2>
<p>In this task, you first create the AWS Glue database. With AWS Glue, you can discover and connect diverse data sources and manage your data in a centralized data catalog.</p>
<p>After you create the database, you add a crawler to extract, transform, and load (ETL) data into the database tables by using a source comma-separated values (CSV) file.</p>
<ol type="1">
<li><p>Choose <strong>Services</strong>, and search for and open <strong>AWS Glue</strong>.</p></li>
<li><p>In the navigation pane, in the <strong>Data Catalog</strong> section, choose <strong>Databases</strong>.</p></li>
<li><p>Choose <strong>Add database</strong>.</p></li>
<li><p>For <strong>Database name</strong>, enter <code>nycitytaxi</code></p></li>
<li><p>Choose <strong>Create database</strong>.</p></li>
<li><p>In the navigation pane, choose <strong>Tables</strong>.</p></li>
</ol>
<p>You can add a table manually or by using a crawler. A crawler is a program that connects to a data store and progresses through a prioritized list of classifiers to determine the schema for your data.</p>
<p>AWS Glue provides classifiers for common file types, such as CSV, JSON, Apache Avro, and others. You can also write your own classifier by using a grok pattern.</p>
<ol type="1">
<li><p>Choose <strong>Add tables using a crawler</strong>.</p></li>
<li><p>For <strong>Crawler name</strong>, enter <code>nytaxicrawler</code> and choose <strong>Next</strong>.</p></li>
<li><p>For <strong>Is your data already mapped to Glue tables?</strong>, keep <strong>Not yet</strong> selected.</p></li>
<li><p>For <strong>Data sources</strong>, choose <strong>Add a data source</strong>.</p></li>
<li><p>For <strong>Data source</strong>, keep <strong>S3</strong>.</p></li>
<li><p>For <strong>S3 path</strong>, paste the following path:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" title="1"><span class="ex">s3</span>://aws-tc-largeobjects/DEV-AWS-MO-Designing_DataLakes/week3/</a></code></pre></div>
<p>This S3 bucket contains the data file, which includes data for all rides from the green taxis in the month of January 2020.</p></li>
<li><p>Keep all other settings for this page at their default values, then choose <strong>Add an S3 data source</strong>.</p></li>
<li><p>Choose <strong>Next</strong>.</p></li>
<li><p>On the <strong>Configure Security Settings</strong> page, from the <strong>Existing IAM role</strong> menu, choose <strong>AWSGlueServiceRoleDefault</strong> and then choose <strong>Next</strong>.</p></li>
<li><p>On the <strong>Set output and scheduling</strong> page, from the <strong>Target database</strong> menu, choose <strong>nycitytaxi</strong>.</p></li>
<li><p>For <strong>Frequency</strong>, keep <strong>On demand</strong> and choose <strong>Next</strong>.</p></li>
<li><p>On the <strong>Review all steps</strong> page, choose <strong>Create crawler</strong>.</p></li>
<li><p>In the <strong>Crawlers</strong> pane, select <strong>nytaxicrawler</strong> and choose <strong>Run</strong>.</p>
<p>When the crawler finishes running, one table is added to the database. After the job stops, you should see that the <strong>Table changes from last run</strong> column now shows <em>1</em>.</p></li>
<li><p>In the navigation pane, choose <strong>Tables</strong>.</p></li>
<li><p>In the <strong>Tables</strong> section, choose the <strong>week3</strong> name link.</p>
<p>This screen describes the table, including its schema, properties, and other information. If you want to look at the schema information, you can choose <strong>Edit schema</strong>.</p></li>
</ol>
<h2 id="task-2-transforming-the-data-from-csv-to-parquet">Task 2: Transforming the data from CSV to Parquet</h2>
<p>In this task, you transform the data from CSV into Apache Parquet format. Parquet organizes data in columns. This format type is more lightweight and brings efficiency compared to row-based files, such as CSV.</p>
<ol type="1">
<li><p>In in the <strong>Data Integration and ETL</strong> section of the navigation pane, choose <strong>Jobs</strong>.</p>
<p>This action opens a new browser tab in AWS Glue Studio.</p></li>
<li><p>In the <strong>Create job</strong> section, keep all the default settings and choose <strong>Create</strong>.</p></li>
<li><p>In the job diagram, choose the <strong>Data source - S3 bucket</strong> node.</p></li>
<li>In the right pane, configure the following settings:
<ul>
<li><strong>S3 source type</strong>: Keep <em>Data Catalog table</em> selected</li>
<li><strong>Database</strong>: <em>nycitytaxi</em></li>
<li><strong>Table</strong>: <em>week3</em></li>
</ul></li>
<li>In the job diagram, choose the <strong>Data target - S3 bucket</strong> node and configure the following settings:
<ul>
<li><strong>Format</strong>: <em>Parquet</em></li>
<li><strong>S3 Target location</strong>: Paste <code>s3://&lt;FMI&gt;/data/</code> and replace the FMI with your bucket name</li>
</ul>
<p>When you replace the FMI with your own value, make sure that you also delete the angle brackets (&lt;&gt;).</p>
<p>Example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" title="1"><span class="ex">s3</span>://glue-934169e0/data/</a></code></pre></div></li>
<li>At the top of the pane, choose the <strong>Job details</strong> tab and configure the following settings:
<ul>
<li><strong>Name</strong>: <code>nytaxiparquet</code></li>
<li><strong>IAM role</strong>: <em>AWSGlueServiceRoleDefault</em></li>
</ul>
<p><strong>Note</strong>: This role grants permissions to resources that AWS Glue needs to automatically generate the <em>nytaxi-csv-parquet</em> script.</p></li>
<li><p>To verify the script, choose the <strong>Script</strong> tab. Feel free to review the script.</p></li>
<li><p>Save the job, and then choose <strong>Run</strong>.</p>
<p>Wait for the job to complete. You can view the status by choosing the <strong>Run details</strong> link (in the system message at the top of the pane) or by choosing the <strong>Runs</strong> tab.</p></li>
<li><p>Return to the main <strong>AWS Glue</strong> console.</p></li>
<li><p>In the navigation pane, choose <strong>Crawlers</strong>.</p></li>
<li><p>Choose <strong>Create crawler</strong>.</p></li>
<li><p>For <strong>Crawler name</strong>, paste <code>nytaxiparquet</code> and choose <strong>Next</strong>.</p></li>
<li><p>For <strong>Is your data already mapped to Glue tables?</strong>, keep <strong>Not yet</strong> selected.</p></li>
<li><p>For <strong>Data sources</strong>, choose <strong>Add a data source</strong>.</p></li>
<li><p>For <strong>S3 path</strong>, paste <code>s3://&lt;FMI&gt;/data/</code>. Replace the FMI with the name of the bucket where the Parquet file is located.</p>
<p>Example:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" title="1"><span class="ex">s3</span>://glue-934169e0/data/</a></code></pre></div></li>
<li><p>Choose <strong>Add an S3 data source</strong> and choose <strong>Next</strong>.</p></li>
<li><p>From the <strong>Existing IAM role</strong> menu, choose <strong>AWSGlueServiceRoleDefault</strong>, and then choose <strong>Next</strong>.</p></li>
<li><p>For <strong>Target database</strong>, select <strong>nycitytaxi</strong>.</p></li>
<li><p>For <strong>Frequency</strong>, keep <strong>Run on demand</strong> selected and then choose <strong>Next</strong>.</p></li>
<li><p>On the <strong>Review and create</strong> page, choose <strong>Create crawler</strong>.</p></li>
<li><p>Select the <strong>nytaxiparquet</strong> crawler and choose <strong>Run</strong>. Wait for the job to finish.</p></li>
<li><p>In the navigation pane, choose <strong>Tables</strong>.</p>
You should see two tables:
<ul>
<li><strong>week3</strong> â€“ The original CSV version from the source bucket</li>
<li><strong>data</strong> â€“ The Parquet table in your S3 bucket</li>
</ul></li>
</ol>
<h2 id="task-3-analyzing-the-data-with-amazon-athena">Task 3: Analyzing the data with Amazon Athena</h2>
<p>Athena is an interactive query service that you can use to analyze data in Amazon S3 with standard SQL. Athena can query CSV data. However, the Parquet file format can significantly reduce the time and cost of querying the data.</p>
<p>In this task, you use Athena to analyze the data in the S3 bucket.</p>
<ol type="1">
<li><p>Choose <strong>Services</strong>, and search for and open <strong>Athena</strong>.</p></li>
<li><p>If you are a new user, choose <strong>Explore the query editor</strong>. For existing users, the query editor might open automatically.</p></li>
<li><p>From the <strong>Database</strong> menu, choose <strong>nycitytaxi</strong>.</p></li>
<li><p>In the query editor, paste the following:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode sql"><code class="sourceCode sql"><a class="sourceLine" id="cb4-1" title="1"><span class="kw">SELECT</span> <span class="op">*</span> <span class="kw">FROM</span> <span class="ot">&quot;nycitytaxi&quot;</span>.<span class="ot">&quot;week3&quot;</span> <span class="kw">LIMIT</span> <span class="dv">10</span>;</a></code></pre></div></li>
<li><p>From the query actions menu (ellipsis), choose <strong>Save as</strong>.</p></li>
<li><p>For both <strong>Query name</strong> and <strong>Query description</strong>, paste <code>taxidata</code> and choose <strong>Save query</strong>.</p></li>
<li><p>At the top of the query editor, choose the <strong>Settings</strong> tab and then choose <strong>Manage</strong>.</p></li>
<li><p>For <strong>Location of query result</strong>, paste the following path for your bucket and replace the FMI with your bucket name.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb5-1" title="1"><span class="ex">s3</span>://<span class="op">&lt;</span>FMI<span class="op">&gt;</span>/sql/</a></code></pre></div>
<p>Example:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb6-1" title="1"><span class="ex">s3</span>://glue-934169e0/sql/</a></code></pre></div></li>
<li><p>Choose <strong>Save</strong>.</p></li>
<li><p>Choose the <strong>Editor</strong> tab and choose <strong>Run</strong>.</p></li>
</ol>
<p>You can now browse the results and see information such as the <em>passenger_count</em>, <em>trip_distance</em>, and <em>tip_amount</em>.</p>
<p>After you query the data, you can optionally connect Amazon Athena with Amazon QuickSight to visualize data through dashboards.</p>
<h2 id="cleaning-up">Cleaning up</h2>
<p>Delete the AWS resources that you created for this exercise by completing the following steps.</p>
<ol type="1">
<li>Delete the Athena query.
<ul>
<li>Open the <strong>Amazon Athena</strong> query editor and choose the <strong>Saved queries</strong> tab.</li>
<li>Delete the <strong>taxidata</strong> query and confirm the deletion.</li>
</ul></li>
<li>Delete the AWS Glue resources.
<ul>
<li>Open the <strong>AWS Glue</strong> dashboard.</li>
<li>In the navigation pane, choose <strong>Crawlers</strong>.</li>
<li>Delete the following crawlers, and confirm their deletion:
<ul>
<li><strong>nytaxicrawler</strong></li>
<li><strong>nytaxiparquet</strong></li>
</ul></li>
<li>In the navigation pane, choose <strong>Tables</strong>.</li>
<li>Delete the following tables and confirm their deletion:
<ul>
<li><strong>data</strong></li>
<li><strong>week3</strong></li>
</ul></li>
<li>In the navigation pane, choose <strong>Databases</strong>.</li>
<li>Delete the <strong>nycitytaxi</strong> database and confirm the deletion.</li>
<li>In the navigation pane, choose <strong>Jobs</strong> (in the <strong>Data Integration and ETL</strong> section).</li>
<li>Delete <strong>nytaxiparquet</strong> and confirm the deletion.</li>
</ul></li>
<li>Delete the S3 buckets.
<ul>
<li>Open the <strong>Amazon S3</strong> dashboard.</li>
<li>Empty and delete the following buckets, and confirm their deletion:
<ul>
<li><strong>glue-</strong> bucket</li>
<li><strong>aws-glue-assets-</strong> bucket</li>
<li><strong>cf-templates-</strong> bucket</li>
</ul></li>
</ul></li>
<li>Delete the CloudFormation stack.
<ul>
<li>Open the <strong>AWS CloudFormation</strong> dashboard.</li>
<li>Delete the <strong>exercise-processing</strong> stack and confirm the deletion.</li>
</ul></li>
<li><em>(Optional)</em> Delete the IAM role. (IAM users, roles, and policies donâ€™t have an associated charge in your AWS account.)
<ul>
<li>Open the <strong>IAM</strong> dashboard.</li>
<li>In the navigation pane, choose <strong>Roles</strong>.</li>
<li>Delete the IAM role for CloudFormation, and confirm the deletion.</li>
</ul></li>
</ol>
<p>Congratulations! You successfully completed the final exercise this course.</p>
<p>In this exercise, you gained a deeper understanding of how to transform and process data in a data lake. You defined a database, configured a crawler, and created a table in AWS Glue. You then transformed the CSV file into Parquet to save on data processing costs, and repeated the steps to create a table for the Parquet data. Finally, you queried the data with Amazon Athena.</p>
<script>
document.body.innerHTML = document.body.innerHTML.replace(/RELATIVE(.+)RELATIVE/g, function (match, capture) {
  let tmp = document.createElement("DIV");
  tmp.innerHTML = capture;
  return new URL(tmp.textContent || tmp.innerText || "", document.baseURI).href;
});
</script>
</body>
<footer>
    <p>Â© 2022 Amazon Web Services, Inc. or its affiliates. All rights reserved. This work may not be reproduced or redistributed, in whole or in part, without prior written permission from Amazon Web Services, Inc. Commercial copying, lending, or selling is prohibited. Corrections, feedback, or other questions? Contact us at <a href="https://support.aws.amazon.com/#/contacts/aws-training" target="_blank">https://support.aws.amazon.com/#/contacts/aws-training</a>. All trademarks are the property of their owners.</p>
</footer>
</html>
